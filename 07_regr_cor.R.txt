###Task 1 Christmas trees
trees<-read.delim("clipboard")
summary(trees)

plot(tree.height~age, data=trees)## plots the scatterplot of height and age variables

lm.trees<-lm(tree.height~age, data=trees) ## Fits linear regression model of tree height depending on children age
lm.trees ## Shows b0 (intercept) and b1 (slope) coefficients in the equation: y = b0 + b1 * x
#...
# Coefficients:
# (Intercept)          age  
#      2.9957      -0.1097 
abline(lm.trees) # intercept and slope are extracted from the model
abline(a=2.9957,b=-0.1097,col="blue") # just to see, what the function is doing
abline(h=1:3,v=c(5,10,15,20),col="grey") #grid
# y = a + b*x
2.9957 - 0.1097 * 5  # predicted height of tree in a family with 5-year old kid
# [1] 2.4472
2.9957 - 0.1097 * 30 # ... 30-year old
# [1] -0.2953
# extrapolation is risky,
# we assume linear relationship on the measured range of X, but the shape may be different for larger range

anova(lm.trees) ## Computes analysis of variance of the regression model 
# Analysis of Variance Table
# 
# Response: tree.height
# Df Sum Sq Mean Sq F value   Pr(>F)   
# age        1 3.7152  3.7152  14.854 0.004849 **
# Residuals  8 2.0008  0.2501   

3.7152/(3.7152+2.0008) ##Computes proportion of explained variability based on Sums of Squares
# [1] 0.649965
summary(lm.trees)
# 
# Call:
# lm(formula = tree.height ~ age, data = trees)
# 
# Residuals:
#      Min       1Q   Median       3Q      Max 
# -0.78154 -0.35686 -0.03737  0.46167  0.56491 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(>|t|)    
# (Intercept)  2.99572    0.34361   8.718 2.34e-05 ***
# age         -0.10968    0.02846  -3.854  0.00485 ** 
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# Residual standard error: 0.5001 on 8 degrees of freedom
# Multiple R-squared:   0.65,  Adjusted R-squared:  0.6062 
# F-statistic: 14.85 on 1 and 8 DF,  p-value: 0.004849


plot(tree.height~age, data=trees) # plots the scatterplot of height and age
# add fitted line with confidence band
  # using standard error of fit
  pred<-data.frame(age=seq(from=min(trees$age),to=max(trees$age),length=100)) # Creates new data frame containing the specified values of the predictor variable
  fit<-predict(lm.trees, newdata=pred, se.fit=T)# Computes fitted values for the values of predictor specified in the newdata parameter. Also computes standard errors of the fit.
  lines(pred$age, fit$fit) # Adds regression line to the plot
  lines(pred$age, fit$fit-qt(0.975,fit$df)*fit$se.fit, lty=2) # Adds the lower confidence limit of the regression line to the plot
  lines(pred$age, fit$fit+qt(0.975,fit$df)*fit$se.fit, lty=2) # Adds the upper confidence limit of the regression line to the plot
# or using confidence interval directly
fit<-as.data.frame(predict(lm.trees, newdata=pred, interval="confidence"))
# This modification computes confidence interval directly, but the outcome is matrix, so the variables cannot be accessed by $-sign,
# so must be converted to data frame (or the variables are to be accessed by indices)
lines(pred$age, fit$fit) # Adds regression line to the plot
lines(pred$age, fit$lwr, lty=2) # Adds the lower confidence limit of the regression line to the plot
lines(pred$age, fit$upr, lty=2) # Adds the upper confidence limit of the regression line to the plot
  # or nicer plot with shaded polygon of conf.band
  fit<-as.data.frame(predict(lm.trees, newdata=pred, interval="confidence"))
  plot(tree.height~age, data=trees,type="n",las=1,ylab="height of tree (m)",
     ylim=c(min(c(fit$lwr,fit$upr,trees$tree.height)),max(c(fit$lwr,fit$upr,trees$tree.height))))
  polygon(x=c(pred$age,rev(pred$age)),y=c(fit$lwr,rev(fit$upr)),col="grey",border=NA)
  lines(pred$age, fit$fit,lwd=2) # Adds regression line to the plot
  points(tree.height~age, data=trees,pch=16)
  
plot(lm.trees) # regression diagnostics
# first plot checks linearity
# second plot checks normality of residuals
# third plot check homogeneity of variance
# fourth plot to be ignored


### Task 2 Correlation matrix
admont<-read.delim("clipboard")
summary(admont)
cor(admont)
cor.test(admont$N,admont$P)
cor.test(~N+P,data=admont)
cor.test(admont) # does not work for whole table
library(Hmisc)
rcorr(as.matrix(admont)) # two matrices, one for r, one for p-values

cor.a<-cor(admont)
library(corrplot)
corrplot(cor.a)
corrplot(cor.a,method="color",type="lower",diag=F)
corrplot.mixed(cor.a,lower="number",upper="ellipse",lower.col="black")

pairs(admont)
pairs(admont,panel=function(x,y){abline(lm(y~x))})

library(psych)
pairs.panels(admont)

### Task 3 Species-Area relationship
sparea<-read.delim("clipboard")
summary(sparea)
plot(sp~area, data=sparea)
lm.sp<-lm(sp~area, data=sparea) # fits the linear model
abline(lm.sp) # linear model does not fit the data well
plot(lm.sp) # shows the regression diagnostics plots (the first one indicates non-linearity)

# calculate model and show plot on x-log and y-log scales
plot(sp~area, data=sparea,log="xy")
plot(log(sp)~log(area),data=sparea)
lm.sp<-lm(log(sp)~log(area),data=sparea) #transform the data and perform analysis
abline(lm.sp)
summary(lm.sp)

# plot the same model on original scale
pred<-data.frame(area=seq(min(sparea$area),max(sparea$area),1000))
fit<-as.data.frame(predict(lm.sp,pred,interval="confidence"))
plot(sp~area, data=sparea)
lines(pred$area,exp(fit$fit)) # back-transform the results to present them on the original scale
lines(pred$area,exp(fit$lwr),lty=2)
lines(pred$area,exp(fit$upr),lty=2)

# extrapolation to surface area of whole continent:
lm.sp
exp(5.0921+0.2662*log(10000000))
exp(predict(lm.sp, data.frame(area=10000000), interval="confidence"))

### Task 4 Football fans
football<-read.delim("clipboard")
cor.test(football$aggressiveness, football$league, method="spearman")# Computes and tests Spearman correlation coefficient (non-parametric)
#   Spearman's rank correlation rho
# data:  football$aggressiveness and football$league
# S = 1789.124, p-value = 0.136
# alternative hypothesis: true rho is not equal to 0
# sample estimates:
#        rho 
# -0.3452061 
plot(football$aggressiveness, football$league)


### Task 5 Cannabis
cannabis<-read.delim("clipboard")
summary(cannabis)

plot(THC~DW, data=cannabis)
can.lm<-lm(THC~DW, data=cannabis)
summary(can.lm)
# Call:
# lm(formula = THC ~ DW, data = cannabis)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -4.9687 -1.4006 -0.2593  1.4734  6.2498 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(>|t|)   
# (Intercept)   1.6650     2.5453   0.654  0.53138   
# DW            1.4160     0.4003   3.537  0.00765 **
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# Residual standard error: 3.211 on 8 degrees of freedom
# Multiple R-squared:  0.6099,  Adjusted R-squared:  0.5612 
# F-statistic: 12.51 on 1 and 8 DF,  p-value: 0.007655

pred<-data.frame(DW=seq(from=min(cannabis$DW), to=max(cannabis$DW), by=0.1))
fit<-data.frame(predict(can.lm, newdata=pred, interval="confidence"))
plot(THC~DW, data=cannabis)
lines(pred$DW, fit$fit)
lines(pred$DW, fit$lwr, lty=2)
lines(pred$DW, fit$upr, lty=2)

# By how much does the THC concentration increase when smoking 3 more grams? 
3*1.416
3*can.lm$coefficients[2]

# illustrate LOESS smoothing
plot(THC~DW, data=cannabis)
lines(loess.smooth(cannabis$DW,cannabis$THC))

lo.pred<-predict(loess(THC~DW, data=cannabis,span=0.65,degree=1),newdata=pred$DW,se=T)
lines(pred$DW,lo.pred$fit,lty=2,lwd=2,col="blue")
lines(pred$DW,lo.pred$fit+qt(0.975,lo.pred$df)*lo.pred$se.fit,lty=2,lwd=1,col="blue")
lines(pred$DW,lo.pred$fit-qt(0.975,lo.pred$df)*lo.pred$se.fit,lty=2,lwd=1,col="blue")


### Task 6 Covid exponential curve
a<-read.delim("clipboard")
plot(daily.cases~index,data=a,type="l")

library(zoo)
lines(x=a$index,y=c(rep(NA,6),rollmean(x=a$daily.cases,k=7)),col="red") # mean of last 7 days

lm.a<-lm(log(daily.cases)~index,data=a) # log-transform dependent variable to fit exponential curve
summary(lm.a)

plot(log(daily.cases)~index,data=a,type="l") # after log-tranformation, the realationship is linear
abline(lm.a)

plot(daily.cases~index,data=a,type="l")
lines(x=1:92,y=exp(5.069599+0.055187*1:92)) # exp-transformed result of linear equation based on log-transformed data


plot(daily.cases~index,data=a,type="l",xlim=c(0,106),ylim=c(0,60000)) # last day has index 92, so 106 makes 2-week prediction
fit<-data.frame(predict(lm.a,newdata=data.frame(index=1:106),interval="confidence")) # confidence interval requires usual assumptions of lm, which are however not met here (the points in time series are not independent)
lines(x=1:106,y=exp(fit$fit))
lines(x=1:106,y=exp(fit$upr),lty=2)
lines(x=1:106,y=exp(fit$lwr),lty=2)
fit<-data.frame(predict(lm.a,newdata=data.frame(index=1:106),interval="prediction")) # prediction interval indicates possible range of values
lines(x=1:106,y=exp(fit$upr),lty=3)
lines(x=1:106,y=exp(fit$lwr),lty=3)

# The reality is more complex, but (log-)linear model provides a simple (and often good) prediction.
# As with all extrapolations, this prediction assumes the same shape of the curve (constant slope), but you know the growth rate varies in time and the growth cannot continue infinitely.
# In this particular case, the assumption is OK in the initial stages when no or mild measures are taken and the growth rate is more or less constant,
# but the prediction fails when anti-epidemic measures or group immunity change the slope.
